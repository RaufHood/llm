{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3a3ac31",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27f90ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.53.0)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting elasticsearch\n",
      "  Downloading elasticsearch-8.15.1-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (4.6.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (4.66.6)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Collecting elastic-transport<9,>=8.13 (from elasticsearch)\n",
      "  Downloading elastic_transport-8.15.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in /home/codespace/.local/lib/python3.12/site-packages (from elastic-transport<9,>=8.13->elasticsearch) (2.2.3)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from elastic-transport<9,>=8.13->elasticsearch) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading elasticsearch-8.15.1-py3-none-any.whl (524 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.6/524.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading elastic_transport-8.15.1-py3-none-any.whl (64 kB)\n",
      "Installing collected packages: python-dotenv, elastic-transport, elasticsearch\n",
      "Successfully installed elastic-transport-8.15.1 elasticsearch-8.15.1 python-dotenv-1.0.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install openai python-dotenv elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47aa20d6-41e6-41e1-8dc3-22d0da688938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from elasticsearch import Elasticsearch\n",
    "import json\n",
    "from tqdm.auto import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14e3e06b-dd09-4cdf-a0d9-d3b9d82a9885",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url = 'http://localhost:11434/v1/',#\n",
    "    api_key = 'ollama'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0fe49f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 'The course has already started, can I still enroll?'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cc1545",
   "metadata": {},
   "source": [
    "## Simple RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1a353eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ databse. \n",
    "Use only the facts in the CONTEXT when answering the question.\n",
    "If the context doesn't contain the answer, output NONE.\n",
    "\n",
    "QUESTION: \n",
    "{question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc70aa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\n",
    "\n",
    "for doc in results:\n",
    "    context += f\"section: {doc['section']} \\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3a1bf30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "section: General course-related questions \n",
      "question: The course has already started. Can I still join it?\n",
      "answer: Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\n",
      "In order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.\n",
      "\n",
      "section: General course-related questions \n",
      "question: Course - Can I still join the course after the start date?\n",
      "answer: Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
      "Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n",
      "\n",
      "section: General course-related questions \n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions \n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions \n",
      "question: Course - What can I do before the course starts?\n",
      "answer: You can start by installing and setting up all the dependencies and requirements:\n",
      "Google cloud account\n",
      "Google Cloud SDK\n",
      "Python 3 (installed with Anaconda)\n",
      "Terraform\n",
      "Git\n",
      "Look over the prerequisites and syllabus to see if you are comfortable with these subjects.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ba14b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.format(question=q, context = context).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dd828a",
   "metadata": {},
   "source": [
    "## Modularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a9337416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "    results = index.search(\n",
    "        query = query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict = boost,\n",
    "        num_results = 5\n",
    "    )   \n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e395af21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search(\"how do I run kafka?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "783e4e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "    You are a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ databse. \n",
    "    Use only the facts in the CONTEXT when answering the question.\n",
    "\n",
    "    QUESTION: \n",
    "    {question}\n",
    "\n",
    "    CONTEXT: \n",
    "    {context}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context += f\"section: {doc['section']} \\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "\n",
    "    prompt = prompt_template.format(question=query, context = context).strip()\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5dd4f546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model = 'gpt-3.5-turbo',\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b1807659",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"how do I run kafka?\"\n",
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "29ad72b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'answer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43manswer\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'answer' is not defined"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c908005",
   "metadata": {},
   "source": [
    "## Using elastic search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90ba94b",
   "metadata": {},
   "source": [
    "Command to run elastic search  \n",
    "docker run -it --name elasticsearch -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" -e \"xpack.security.enabled=false\" docker.elastic.co/elasticsearch/elasticsearch:8.4.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f98c58",
   "metadata": {},
   "source": [
    "http get request to local host  \n",
    "curl http://localhost:9200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f92e4c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"documents.json\", \"rt\") as f_in:\n",
    "    docs_raw = json.load(f_in)\n",
    "    \n",
    "documents = []\n",
    "\n",
    "#docs_raw[2] # 3 courses\n",
    "for course_dict in docs_raw:\n",
    "    for doc in course_dict['documents']:\n",
    "        doc['course'] = course_dict['course']\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "76ba3335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': 'e79cd6cdd621', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'iovZK3DNTmmzBYF-RohZIw', 'version': {'number': '8.4.3', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '42f05b9372a9a4a470db3b52817899b99a76ee73', 'build_date': '2022-10-04T07:17:24.662462378Z', 'build_snapshot': False, 'lucene_version': '9.3.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client = Elasticsearch('http://localhost:9200')\n",
    "es_client.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d039bfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"}\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3fb282c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions'})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"course-questions\"\n",
    "\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9a2e1d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 948/948 [00:28<00:00, 33.50it/s]\n"
     ]
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "936922e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'I just discovered the course, can I still join it?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d33b287a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query):\n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^3\", \"text\", \"section\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": \"data-engineering-zoomcamp\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "    result_docs = []\n",
    "\n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b177d0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = elastic_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fc1ee887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "    You are a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ databse. \n",
    "    Use only the facts in the CONTEXT when answering the question.\n",
    "\n",
    "    QUESTION: \n",
    "    {question}\n",
    "\n",
    "    CONTEXT: \n",
    "    {context}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context += f\"section: {doc['section']} \\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "\n",
    "    prompt = prompt_template.format(question=query, context = context).strip()\n",
    "\n",
    "    return prompt\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model = 'phi3',\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7a44b2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = elastic_search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea7a5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rag(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060a1696",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616bdced",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
