{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running model in CPU using Ollama\n",
    "- Step 1:  run in terminal'\n",
    "```curl -fsSL https://ollama.com/install.sh | sh```  \n",
    "- Step 2:\n",
    "```ollama start```\n",
    "- Step 3:  in new terminal\n",
    "```ollama run phi3```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "q = \"I just discovered the course can I still join it?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download the model to use it in docker\n",
    "- docker ps # show name of the container\n",
    "- docker exec -it ollama bash\n",
    "- ollama pull phi3"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
